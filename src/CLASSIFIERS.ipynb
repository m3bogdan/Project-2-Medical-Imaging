{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "data_path = \"C:/Users/annam/Desktop/ITU/2nd_sem/02_First_Year_Project/2nd_project/Data/full_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_frame = pd.DataFrame(data = df[\"img_id\"], columns = df[\"diagnostic\"])\n",
    "#new_frame\n",
    "\n",
    "new_df=df[['img_id','diagnostic']]\n",
    "new_df.loc[new_df['diagnostic'].isin(['BCC', 'MEL', 'SCC']), 'diagnostic'] = int(1)\n",
    "new_df.loc[new_df['diagnostic'].isin(['ACK', 'NEV', 'SEK']), 'diagnostic'] = int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "\n",
    "import functions\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "folder_path_in = \"C:/Users/annam/Desktop/Color_mask/Color_mask/Training\"\n",
    "def extract_features(folder_path_in):\n",
    "    # Create a list of image filenames\n",
    "    feature_1 = []\n",
    "    feature_2 = []\n",
    "    feature_3 = []\n",
    "    feature_4 = []\n",
    "    feature_5 = []\n",
    "    feature_6 = []\n",
    "    feature_7 = []\n",
    "    #Iterate through all the jpg and png files in the selected folder\n",
    "    for filename in [f for f in os.listdir(folder_path_in) if f.endswith('.jpg') or f.endswith('.png')]:\n",
    "        \n",
    "        #Read in the image\n",
    "        image_path = folder_path_in + \"/\" + filename\n",
    "        original = io.imread(image_path)\n",
    "\n",
    "        # Ignore the alpha channel (e.g. transparency )\n",
    "        if original.shape[-1] == 4:\n",
    "            original = original[..., :3]\n",
    "        \n",
    "        feature_1.append(functions.measure_pigment_network(original))\n",
    "        feature_2.append(functions.measure_blue_veil(original))\n",
    "        feature_3.append(functions.measure_vascular(original))\n",
    "        feature_4.append(functions.measure_globules(original))\n",
    "        feature_5.append(functions.measure_streaks(original))\n",
    "        feature_6.append(functions.measure_irregular_pigmentation(original))\n",
    "        feature_7.append(functions.measure_regression(original))\n",
    "    return feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "features_df = pd.DataFrame()\n",
    "for filename in os.listdir(folder_path_in):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "        file_names.append(filename)\n",
    "\n",
    "features_df = pd.DataFrame({'img_id': file_names})\n",
    "\n",
    "def featurized_df(feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7):\n",
    "   \n",
    "\n",
    "\n",
    "    features_df[\"1: pigment network\"] = feature_1\n",
    "    features_df[\"2: Blue veil\"] = feature_2\n",
    "    features_df[\"3: Vascular\"] = feature_3\n",
    "    features_df[\"4: Globules\"] = feature_4\n",
    "    features_df[\"5: Streaks\"] = feature_5\n",
    "    features_df[\"6: Pigmentation\"] = feature_6\n",
    "    features_df[\"7: Regression\"] = feature_7\n",
    "\n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df1 and df2 are your DataFrames\n",
    "# Assuming 'img_id' is the column name containing the image IDs\n",
    "\n",
    "# Check if the img_id values are the same in both DataFrames\n",
    "df_merged = pd.merge(new_df, features_df, on='img_id', how='inner')\n",
    "\n",
    "# Create a new column called 'diagnosed' based on the comparison\n",
    "#df_merged['diagnosed'] = True\n",
    "\n",
    "# If you want to fill the 'diagnosed' column with False for non-matching img_id values, uncomment the following line:\n",
    "#df_merged['diagnosed'].fillna(False, inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_merged.copy()\n",
    "X.drop(\"img_id\", axis = 1, inplace = True)\n",
    "X.drop(\"diagnostic\", axis = 1, inplace = True)\n",
    "Y = df_merged[\"diagnostic\"].astype(int)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m classifier \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[0;32m      4\u001b[0m \u001b[39m#Training the classifier\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m classifier \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m      7\u001b[0m prediction \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:186\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    184\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 186\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    187\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    188\u001b[0m )\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    190\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_X_params:\n\u001b[0;32m    578\u001b[0m     check_X_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 579\u001b[0m X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_X_params)\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_y_params:\n\u001b[0;32m    581\u001b[0m     check_y_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[0;32m    780\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[39m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "#Training the classifier\n",
    "classifier = classifier.fit(X_train, Y_train)\n",
    "\n",
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "cm = confusion_matrix(Y_test, prediction, labels = [0, 1])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "feature_names = X.columns\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "_ = tree.plot_tree(classifier, feature_names= feature_names, class_names= {0:\"cancer\",1: \"no cancer\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cla = LogisticRegression()\n",
    "\n",
    "cla = cla.fit(X_train, Y_train)\n",
    "prediction = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, prediction, labels = [0, 1])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classif = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "classif = cla.fit(X_train, Y_train)\n",
    "pred = classifier.predict(X_test)\n",
    "conf = confusion_matrix(Y_test, pred, labels = [0, 1])\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "\n",
    "# Perform cross-validation for Linear Regression\n",
    "linear_regression_scores = cross_val_score(cla, X_train, Y_train, cv=5)\n",
    "linear_regression_mean_accuracy = linear_regression_scores.mean()\n",
    "\n",
    "# Perform cross-validation for KNN\n",
    "knn_scores = cross_val_score(classif, X_train, Y_train, cv=5)\n",
    "knn_mean_accuracy = knn_scores.mean()\n",
    "\n",
    "# Perform cross-validation for Decision Tree\n",
    "tree_scores = cross_val_score(classifier, X_train, Y_train, cv=5)\n",
    "tree_mean_accuracy = tree_scores.mean()\n",
    "\n",
    "# Calculate F1 score for Linear Regression\n",
    "y_pred_linear_regression = cla.predict(X_test)\n",
    "y_pred_linear_regression = [0 if val < 0.5 else 1 for val in y_pred_linear_regression]\n",
    "f1_linear_regression = f1_score(Y_test, y_pred_linear_regression)\n",
    "\n",
    "# Calculate F1 score for KNN\n",
    "y_pred_knn = classif.predict(X_test)\n",
    "f1_knn = f1_score(Y_test, y_pred_knn)\n",
    "\n",
    "# Calculate F1 score for Tree\n",
    "y_pred_tree = classifier.predict(X_test)\n",
    "f1_tree = f1_score(Y_test, y_pred_tree)\n",
    "\n",
    "# Calculate AUC-ROC score for Linear Regression\n",
    "auc_roc_linear_regression = roc_auc_score(Y_test, y_pred_linear_regression)\n",
    "\n",
    "# Calculate AUC-ROC score for KNN\n",
    "auc_roc_knn = roc_auc_score(Y_test, y_pred_knn)\n",
    "\n",
    "# Calculate AUC-ROC score for KNN\n",
    "auc_roc_tree = roc_auc_score(Y_test, y_pred_tree)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Linear Regression Cross-Validation Accuracy:\", linear_regression_mean_accuracy)\n",
    "print(\"KNN Cross-Validation Accuracy:\", knn_mean_accuracy)\n",
    "print(\"Tree Cross-Validation Accuracy:\", tree_mean_accuracy)\n",
    "print(\"Linear Regression F1 Score:\", f1_linear_regression)\n",
    "print(\"KNN F1 Score:\", f1_knn)\n",
    "print(\"Tree F1 Score:\", f1_tree)\n",
    "print(\"Linear Regression AUC-ROC Score:\", auc_roc_linear_regression)\n",
    "print(\"KNN AUC-ROC Score:\", auc_roc_knn)\n",
    "print(\"Tree AUC-ROC Score:\", auc_roc_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the classifier\n",
    "import pickle\n",
    "pickle.dump(classif, open(\"C:/Users/annam/Desktop/Trained_classifiers/KNN_2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annam\\Desktop\\ITU\\2nd_sem\\02_First_Year_Project\\2nd_project\\Project-2-Medical-Imaging\\src\\functions.py:160: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circularity = 4 * 3.1415 * (area / (perimeter ** 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but KNeighborsClassifier is expecting 7 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m image_features \u001b[39m=\u001b[39m extract_features(image_path)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Make the prediction using the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(image_features)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Convert the numerical prediction back to the corresponding label\u001b[39;00m\n\u001b[0;32m     18\u001b[0m label_mapping \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbenign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmalignant\u001b[39m\u001b[39m'\u001b[39m}\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:806\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    804\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    805\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 806\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    808\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[0;32m    809\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8 features, but KNeighborsClassifier is expecting 7 features as input."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the trained model from the saved file\n",
    "with open(\"C:/Users/annam/Desktop/Trained_classifiers/KNN_2.pkl\", 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Assuming you have a new image to predict\n",
    "image_path = \"C:/Users/annam/Desktop/Vascular/Masked\"\n",
    "\n",
    "\n",
    "# Extract features from the preprocessed image\n",
    "image_features = extract_features(image_path)\n",
    "\n",
    "# Make the prediction using the model\n",
    "prediction = model.predict(image_features)\n",
    "\n",
    "# Convert the numerical prediction back to the corresponding label\n",
    "label_mapping = {0: 'benign', 1: 'malignant'}\n",
    "predicted_label = label_mapping[prediction[0]]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = pickle.load(open(\"C:/Users/annam/Desktop/Trained_classifiers/KNN.pkl\", \"rb\"))\n",
    "KNN_model.predict(io.imread(\"C:/Users/annam/Desktop/Vascular/Masked/image5.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
