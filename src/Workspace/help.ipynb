{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Functions2\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage import color, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_log\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the image\n",
    "image = cv2.imread(r'C:\\Users\\serru\\OneDrive\\Documents\\Project2\\Project-2-Medical-Imaging\\data\\ColorMask\\Test\\PAT_56_86_479.png')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage import color, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_log\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Function to perform PCA on a given feature vector\n",
    "def apply_pca(feature_vector):\n",
    "    pca = PCA(n_components=2)  # You can adjust the number of components as per your requirement\n",
    "    transformed = pca.fit_transform(feature_vector)\n",
    "    return transformed\n",
    "\n",
    "# Function to measure pigment network\n",
    "def measure_pigment_network(image):\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, _, _ = cv2.split(lab_image)\n",
    "\n",
    "    enhanced_l_channel = cv2.equalizeHist(l_channel)\n",
    "    _, binary_mask = cv2.threshold(enhanced_l_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    total_pixels = np.prod(binary_mask.shape[:2])\n",
    "    pigment_pixels = np.count_nonzero(binary_mask)\n",
    "    coverage_percentage = (pigment_pixels / total_pixels) * 100\n",
    "\n",
    "    return np.array([[coverage_percentage]])  # Reshape the scalar value into a 2D array\n",
    "\n",
    "\n",
    "# Function to measure blue veil\n",
    "def measure_blue_veil(image):\n",
    "    height, width, _ = image.shape\n",
    "    count = 0\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            b, g, r = image[y, x]\n",
    "\n",
    "            if b > 60 and (r - 46 < g) and (g < r + 15):\n",
    "                count += 1\n",
    "\n",
    "    return np.array([[count]])  # Reshape the scalar value into a 2D array\n",
    "\n",
    "\n",
    "# Function to measure vascular\n",
    "def measure_vascular(image):\n",
    "    red_channel = image[:, :, 0]\n",
    "    enhanced_red_channel = exposure.adjust_gamma(red_channel, gamma=1)\n",
    "    enhanced_image = image.copy()\n",
    "    enhanced_image[:, :, 0] = enhanced_red_channel\n",
    "    hsv_img = color.rgb2hsv(enhanced_image)\n",
    "\n",
    "    lower_red1 = np.array([0, 40/100, 00/100])\n",
    "    upper_red1 = np.array([25/360, 1, 1])\n",
    "    mask1 = np.logical_and(np.all(hsv_img >= lower_red1, axis=-1), np.all(hsv_img <= upper_red1, axis=-1))\n",
    "\n",
    "    lower_red2 = np.array([330/360, 40/100, 00/100])  # Lower limit for red hue, saturation, and value\n",
    "    upper_red2 = np.array([1, 1, 1])  # Upper limit for red hue, saturation, and value\n",
    "    mask2 = np.logical_and(np.all(hsv_img >= lower_red2, axis=-1), np.all(hsv_img <= upper_red2, axis=-1))\n",
    "\n",
    "    mask = np.logical_or(mask1, mask2)\n",
    "\n",
    "    return np.array([[np.sum(mask)]])  # Reshape the scalar value into a 2D array\n",
    "\n",
    "\n",
    "# Function to measure globules\n",
    "def measure_globules(image):\n",
    "    image_gray = rgb2gray(image)\n",
    "    inverted_image = 1 - image_gray\n",
    "\n",
    "    blobs_doh = blob_log(inverted_image, min_sigma=1, max_sigma=4, num_sigma=50, threshold=.05)\n",
    "    blobs_doh[:, 2] = blobs_doh[:, 2] * sqrt(2)\n",
    "    blob_amount = len(blobs_doh)\n",
    "\n",
    "    return np.array([[blob_amount]])  # Reshape the scalar value into a 2D array\n",
    "\n",
    "\n",
    "# Function to measure streaks\n",
    "def measure_streaks(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    lesion_area = cv2.contourArea(contours[0])\n",
    "    border_perimeter = cv2.arcLength(contours[0], True)\n",
    "    if lesion_area == 0:\n",
    "        irregularity = 0 \n",
    "    else:\n",
    "        irregularity = (border_perimeter ** 2) / (4 * np.pi * lesion_area)\n",
    "\n",
    "    return np.array([[irregularity]])  # Reshape the scalar value into a 2D array\n",
    "\n",
    "\n",
    "# Function to measure irregular pigmentation\n",
    "def measure_irregular_pigmentation(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    threshold = threshold_otsu(gray)\n",
    "    binary = gray > threshold\n",
    "    labeled_image = label(binary)\n",
    "\n",
    "    min_rows, min_cols, max_rows, max_cols = [], [], [], []\n",
    "\n",
    "    for region in regionprops(labeled_image):\n",
    "        area = region.area\n",
    "        perimeter = region.perimeter\n",
    "\n",
    "        if perimeter == 0:\n",
    "            continue\n",
    "\n",
    "        circularity = 4 * np.pi * (area / (perimeter ** 2))\n",
    "\n",
    "        if circularity < 0.6:\n",
    "            min_row, min_col, max_row, max_col = region.bbox\n",
    "            min_rows.append(min_row)\n",
    "            min_cols.append(min_col)\n",
    "            max_rows.append(max_row)\n",
    "            max_cols.append(max_col)\n",
    "\n",
    "    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    total_pixels = np.prod(binary_mask.shape[:2])\n",
    "    irregular_pixels = np.count_nonzero(binary_mask)\n",
    "    coverage_percentage = (irregular_pixels / total_pixels) * 100\n",
    "\n",
    "    return np.array([[coverage_percentage]])  # Reshape the scalar value into a 2D array\n",
    "\n",
    "\n",
    "# Function to measure regression\n",
    "def measure_regression(image):\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_color = np.array([0, 0, 150])\n",
    "    upper_color = np.array([180, 30, 255])\n",
    "    mask = cv2.inRange(hsv_img, lower_color, upper_color)\n",
    "    num_pixels = cv2.countNonZero(mask)\n",
    "\n",
    "    return np.array([[num_pixels]])  # Reshape the scalar value into a 2D array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m regression_feature \u001b[39m=\u001b[39m measure_regression(image)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Apply PCA to each feature vector\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m pigment_network_pca \u001b[39m=\u001b[39m apply_pca(pigment_network_feature)\n\u001b[0;32m     15\u001b[0m blue_veil_pca \u001b[39m=\u001b[39m apply_pca(blue_veil_feature)\n\u001b[0;32m     16\u001b[0m vascular_pca \u001b[39m=\u001b[39m apply_pca(vascular_feature)\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mapply_pca\u001b[1;34m(feature_vector)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_pca\u001b[39m(feature_vector):\n\u001b[0;32m     16\u001b[0m     pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# You can adjust the number of components as per your requirement\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     transformed \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(feature_vector)\n\u001b[0;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m transformed\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    463\u001b[0m U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_full(X, n_components)\n\u001b[0;32m    513\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    514\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_truncated(X, n_components, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:526\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    523\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmle\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is only supported if n_samples >= n_features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         )\n\u001b[0;32m    525\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n_components \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m--> 526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m must be between 0 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmin(n_samples, n_features)=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msvd_solver=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_components, \u001b[39mmin\u001b[39m(n_samples, n_features))\n\u001b[0;32m    530\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[39m# Center data\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "image = cv2.imread(r'C:\\Users\\serru\\OneDrive\\Documents\\Project2\\Project-2-Medical-Imaging\\data\\ColorMask\\Test\\PAT_998_17_641.png')\n",
    "\n",
    "# Compute feature vectors\n",
    "pigment_network_feature = measure_pigment_network(image)\n",
    "blue_veil_feature = measure_blue_veil(image)\n",
    "vascular_feature = measure_vascular(image)\n",
    "globules_feature = measure_globules(image)\n",
    "streaks_feature = measure_streaks(image)\n",
    "irregular_pigmentation_feature = measure_irregular_pigmentation(image)\n",
    "regression_feature = measure_regression(image)\n",
    "\n",
    "# Apply PCA to each feature vector\n",
    "pigment_network_pca = apply_pca(pigment_network_feature)\n",
    "blue_veil_pca = apply_pca(blue_veil_feature)\n",
    "vascular_pca = apply_pca(vascular_feature)\n",
    "globules_pca = apply_pca(globules_feature)\n",
    "streaks_pca = apply_pca(streaks_feature)\n",
    "irregular_pigmentation_pca = apply_pca(irregular_pigmentation_feature)\n",
    "regression_pca = apply_pca(regression_feature)\n",
    "\n",
    "# Print the transformed feature vectors after PCA\n",
    "print(\"Pigment Network PCA:\")\n",
    "print(pigment_network_pca)\n",
    "\n",
    "print(\"Blue Veil PCA:\")\n",
    "print(blue_veil_pca)\n",
    "\n",
    "print(\"Vascular PCA:\")\n",
    "print(vascular_pca)\n",
    "\n",
    "print(\"Globules PCA:\")\n",
    "print(globules_pca)\n",
    "\n",
    "print(\"Streaks PCA:\")\n",
    "print(streaks_pca)\n",
    "\n",
    "print(\"Irregular Pigmentation PCA:\")\n",
    "print(irregular_pigmentation_pca)\n",
    "\n",
    "print(\"Regression PCA:\")\n",
    "print(regression_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pigment Network Feature:\n",
      "18.05419921875\n",
      "Blue Veil Feature:\n",
      "3899\n",
      "Vascular Feature:\n",
      "0\n",
      "Globules Feature:\n",
      "80\n",
      "Streaks Feature:\n",
      "1.2732395447351628\n",
      "Irregular Pigmentation Feature:\n",
      "25.82244873046875\n",
      "Regression Feature:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage import color, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_log\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# Function to measure pigment network\n",
    "def measure_pigment_network(image):\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, _, _ = cv2.split(lab_image)\n",
    "\n",
    "    enhanced_l_channel = cv2.equalizeHist(l_channel)\n",
    "    _, binary_mask = cv2.threshold(enhanced_l_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    total_pixels = np.prod(binary_mask.shape[:2])\n",
    "    pigment_pixels = np.count_nonzero(binary_mask)\n",
    "    coverage_percentage = (pigment_pixels / total_pixels) * 100\n",
    "\n",
    "    return coverage_percentage\n",
    "\n",
    "# Function to measure blue veil\n",
    "def measure_blue_veil(image):\n",
    "    height, width, _ = image.shape\n",
    "    count = 0\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            b, g, r = image[y, x]\n",
    "\n",
    "            if b > 60 and (r - 46 < g) and (g < r + 15):\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "# Function to measure vascular\n",
    "def measure_vascular(image):\n",
    "    red_channel = image[:, :, 0]\n",
    "    enhanced_red_channel = exposure.adjust_gamma(red_channel, gamma=1)\n",
    "    enhanced_image = image.copy()\n",
    "    enhanced_image[:, :, 0] = enhanced_red_channel\n",
    "    hsv_img = color.rgb2hsv(enhanced_image)\n",
    "\n",
    "    lower_red1 = np.array([0, 40/100, 00/100])\n",
    "    upper_red1 = np.array([25/360, 1, 1])\n",
    "    mask1 = np.logical_and(np.all(hsv_img >= lower_red1, axis=-1), np.all(hsv_img <= upper_red1, axis=-1))\n",
    "\n",
    "    lower_red2 = np.array([330/360, 40/100, 00/100])  # Lower limit for red hue, saturation, and value\n",
    "    upper_red2 = np.array([1, 1, 1])  # Upper limit for red hue, saturation, and value\n",
    "    mask2 = np.logical_and(np.all(hsv_img >= lower_red2, axis=-1), np.all(hsv_img <= upper_red2, axis=-1))\n",
    "\n",
    "    mask = np.logical_or(mask1, mask2)\n",
    "\n",
    "    return np.sum(mask)\n",
    "\n",
    "# Function to measure globules\n",
    "def measure_globules(image):\n",
    "    image_gray = rgb2gray(image)\n",
    "    inverted_image = 1 - image_gray\n",
    "\n",
    "    blobs_doh = blob_log(inverted_image, min_sigma=1, max_sigma=4, num_sigma=50, threshold=.05)\n",
    "    blobs_doh[:, 2] = blobs_doh[:, 2] * sqrt(2)\n",
    "    blob_amount = len(blobs_doh)\n",
    "\n",
    "    return blob_amount\n",
    "\n",
    "# Function to measure streaks\n",
    "def measure_streaks(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    lesion_area = cv2.contourArea(contours[0])\n",
    "    border_perimeter = cv2.arcLength(contours[0], True)\n",
    "    if lesion_area == 0:\n",
    "        irregularity = 0\n",
    "    else:\n",
    "        irregularity = (border_perimeter ** 2) / (4 * np.pi * lesion_area)\n",
    "\n",
    "    return irregularity\n",
    "\n",
    "# Function to measure irregular pigmentation\n",
    "def measure_irregular_pigmentation(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    threshold = threshold_otsu(gray)\n",
    "    binary = gray > threshold\n",
    "    labeled_image = label(binary)\n",
    "\n",
    "    min_rows, min_cols, max_rows, max_cols = [], [], [], []\n",
    "\n",
    "    for region in regionprops(labeled_image):\n",
    "        area = region.area\n",
    "        perimeter = region.perimeter\n",
    "\n",
    "        if perimeter == 0:\n",
    "            continue\n",
    "\n",
    "        circularity = 4 * np.pi * (area / (perimeter ** 2))\n",
    "\n",
    "        if circularity < 0.6:\n",
    "            min_row, min_col, max_row, max_col = region.bbox\n",
    "            min_rows.append(min_row)\n",
    "            min_cols.append(min_col)\n",
    "            max_rows.append(max_row)\n",
    "            max_cols.append(max_col)\n",
    "\n",
    "    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    total_pixels = np.prod(binary_mask.shape[:2])\n",
    "    irregular_pixels = np.count_nonzero(binary_mask)\n",
    "    coverage_percentage = (irregular_pixels / total_pixels) * 100\n",
    "\n",
    "    return coverage_percentage\n",
    "\n",
    "# Function to measure regression\n",
    "def measure_regression(image):\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_color = np.array([0, 0, 150])\n",
    "    upper_color = np.array([180, 30, 255])\n",
    "    mask = cv2.inRange(hsv_img, lower_color, upper_color)\n",
    "    num_pixels = cv2.countNonZero(mask)\n",
    "\n",
    "    return num_pixels\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(r'C:\\Users\\serru\\OneDrive\\Documents\\Project2\\Project-2-Medical-Imaging\\data\\ColorMask\\Test\\PAT_270_417_257.png')\n",
    "\n",
    "# Compute feature vectors\n",
    "pigment_network_feature = measure_pigment_network(image)\n",
    "blue_veil_feature = measure_blue_veil(image)\n",
    "vascular_feature = measure_vascular(image)\n",
    "globules_feature = measure_globules(image)\n",
    "streaks_feature = measure_streaks(image)\n",
    "irregular_pigmentation_feature = measure_irregular_pigmentation(image)\n",
    "regression_feature = measure_regression(image)\n",
    "\n",
    "# Print the feature vectors\n",
    "print(\"Pigment Network Feature:\")\n",
    "print(pigment_network_feature)\n",
    "\n",
    "print(\"Blue Veil Feature:\")\n",
    "print(blue_veil_feature)\n",
    "\n",
    "print(\"Vascular Feature:\")\n",
    "print(vascular_feature)\n",
    "\n",
    "print(\"Globules Feature:\")\n",
    "print(globules_feature)\n",
    "\n",
    "print(\"Streaks Feature:\")\n",
    "print(streaks_feature)\n",
    "\n",
    "print(\"Irregular Pigmentation Feature:\")\n",
    "print(irregular_pigmentation_feature)\n",
    "\n",
    "print(\"Regression Feature:\")\n",
    "print(regression_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract features from an image\n",
    "def extract_features(image):\n",
    "    # Call your feature measurement functions here and return a feature vector\n",
    "    feature_vector = [\n",
    "        measure_pigment_network(image),\n",
    "        measure_blue_veil(image),\n",
    "        measure_vascular(image),\n",
    "        measure_globules(image),\n",
    "        measure_streaks(image),\n",
    "        measure_irregular_pigmentation(image),\n",
    "        measure_regression(image)\n",
    "    ]\n",
    "    return feature_vector\n",
    "\n",
    "# Read image names and labels from the CSV file\n",
    "csv_file = r'C:\\Users\\serru\\OneDrive\\Documents\\Project2\\Project-2-Medical-Imaging\\data\\full_data.csv'  # Replace with your CSV file name\n",
    "image_names = []\n",
    "labels = []\n",
    "with open(csv_file, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header row\n",
    "    for row in reader:\n",
    "        image_names.append(row[0])  # Assuming image names are in the first column\n",
    "        labels.append(row[1])  # Assuming labels are in the second column\n",
    "\n",
    "# Example usage\n",
    "images = []\n",
    "for image_name in image_names:\n",
    "    # Load your images based on the image names and append them to the images list\n",
    "    image = cv2.imread(image_name)\n",
    "    images.append(image)\n",
    "\n",
    "feature_matrix = []\n",
    "for image in images:\n",
    "    features = extract_features(image)\n",
    "    feature_matrix.append(features)\n",
    "\n",
    "X = np.array(feature_matrix)\n",
    "y = np.array(labels)\n",
    "\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "for i, mi in enumerate(mi_scores):\n",
    "    print(f\"Feature {i+1}: {mi}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m features \u001b[39m=\u001b[39m [feature1, feature2]\n\u001b[0;32m     49\u001b[0m \u001b[39m# Perform LDA on the features\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m transformed_features \u001b[39m=\u001b[39m perform_lda(features)\n\u001b[0;32m     52\u001b[0m \u001b[39m# Print the transformed features\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTransformed features:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m, in \u001b[0;36mperform_lda\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Perform LDA\u001b[39;00m\n\u001b[0;32m     17\u001b[0m lda \u001b[39m=\u001b[39m LinearDiscriminantAnalysis(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m X_lda \u001b[39m=\u001b[39m lda\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Return the transformed features\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m X_lda\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage import color, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_log\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Function to perform LDA on the features\n",
    "def perform_lda(features):\n",
    "    # Convert the list of features into a numpy array\n",
    "    X = np.array(features)\n",
    "\n",
    "    # Perform LDA\n",
    "    lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "    X_lda = lda.fit_transform(X)\n",
    "\n",
    "    # Return the transformed features\n",
    "    return X_lda\n",
    "\n",
    "# Example usage\n",
    "image1 = cv2.imread(r'C:\\Users\\serru\\OneDrive\\Documents\\Project2\\Project-2-Medical-Imaging\\data\\ColorMask\\Test\\PAT_333_1469_499.png')\n",
    "image2 = cv2.imread(r'C:\\Users\\serru\\OneDrive\\Documents\\Project2\\Project-2-Medical-Imaging\\data\\ColorMask\\Test\\PAT_38_54_234.png')\n",
    "\n",
    "feature1 = [\n",
    "    measure_pigment_network(image1),\n",
    "    measure_blue_veil(image1),\n",
    "    measure_vascular(image1),\n",
    "    measure_globules(image1),\n",
    "    measure_streaks(image1),\n",
    "    measure_irregular_pigmentation(image1),\n",
    "    measure_regression(image1)\n",
    "]\n",
    "\n",
    "feature2 = [\n",
    "    measure_pigment_network(image2),\n",
    "    measure_blue_veil(image2),\n",
    "    measure_vascular(image2),\n",
    "    measure_globules(image2),\n",
    "    measure_streaks(image2),\n",
    "    measure_irregular_pigmentation(image2),\n",
    "    measure_regression(image2)\n",
    "]\n",
    "\n",
    "features = [feature1, feature2]\n",
    "\n",
    "# Perform LDA on the features\n",
    "transformed_features = perform_lda(features)\n",
    "\n",
    "# Print the transformed features\n",
    "print(\"Transformed features:\")\n",
    "print(transformed_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
