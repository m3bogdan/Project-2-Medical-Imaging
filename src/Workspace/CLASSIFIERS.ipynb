{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>smoke</th>\n",
       "      <th>drink</th>\n",
       "      <th>background_father</th>\n",
       "      <th>background_mother</th>\n",
       "      <th>age</th>\n",
       "      <th>pesticide</th>\n",
       "      <th>gender</th>\n",
       "      <th>skin_cancer_history</th>\n",
       "      <th>...</th>\n",
       "      <th>diameter_2</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>itch</th>\n",
       "      <th>grew</th>\n",
       "      <th>hurt</th>\n",
       "      <th>changed</th>\n",
       "      <th>bleed</th>\n",
       "      <th>elevation</th>\n",
       "      <th>img_id</th>\n",
       "      <th>biopsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAT_38</td>\n",
       "      <td>54.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>52.0</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>BCC</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>PAT_38_54_234.png</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAT_42</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>38.0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BCC</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>UNK</td>\n",
       "      <td>True</td>\n",
       "      <td>UNK</td>\n",
       "      <td>True</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>PAT_42_58_13.png</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAT_46</td>\n",
       "      <td>881.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>POMERANIA</td>\n",
       "      <td>POMERANIA</td>\n",
       "      <td>55.0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BCC</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>PAT_46_881_939.png</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAT_98</td>\n",
       "      <td>152.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>61.0</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BCC</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "      <td>UNK</td>\n",
       "      <td>False</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>PAT_98_152_562.png</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>PAT_2109</td>\n",
       "      <td>4598.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEK</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>PAT_2109_4598_112.png</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEST GROUP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10%</td>\n",
       "      <td>2 per group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VALIDATION GROUP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15%</td>\n",
       "      <td>3 per group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAINING SET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75%</td>\n",
       "      <td>15 per group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100%</td>\n",
       "      <td>20 per group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  lesion_id  smoke  drink background_father background_mother  \\\n",
       "0          BCC        NaN    NaN    NaN               NaN               NaN   \n",
       "1       PAT_38       54.0  False  False           GERMANY           GERMANY   \n",
       "2       PAT_42       58.0  False  False           GERMANY           GERMANY   \n",
       "3       PAT_46      881.0  False  False         POMERANIA         POMERANIA   \n",
       "4       PAT_98      152.0  False  False            BRAZIL            BRAZIL   \n",
       "..         ...        ...    ...    ...               ...               ...   \n",
       "125   PAT_2109     4598.0    NaN    NaN               NaN               NaN   \n",
       "126        NaN        NaN    NaN    NaN               NaN        TEST GROUP   \n",
       "127        NaN        NaN    NaN    NaN               NaN  VALIDATION GROUP   \n",
       "128        NaN        NaN    NaN    NaN               NaN      TRAINING SET   \n",
       "129        NaN        NaN    NaN    NaN               NaN               NaN   \n",
       "\n",
       "      age pesticide        gender skin_cancer_history  ... diameter_2  \\\n",
       "0     NaN       NaN           NaN                 NaN  ...        NaN   \n",
       "1    52.0      TRUE          MALE                True  ...       12.0   \n",
       "2    38.0     FALSE        FEMALE                True  ...        9.0   \n",
       "3    55.0     FALSE        FEMALE                True  ...        5.0   \n",
       "4    61.0     FALSE          MALE               False  ...        7.0   \n",
       "..    ...       ...           ...                 ...  ...        ...   \n",
       "125  55.0       NaN           NaN                 NaN  ...        NaN   \n",
       "126   NaN       10%   2 per group                 NaN  ...        NaN   \n",
       "127   NaN       15%   3 per group                 NaN  ...        NaN   \n",
       "128   NaN       75%  15 per group                 NaN  ...        NaN   \n",
       "129   NaN      100%  20 per group                 NaN  ...        NaN   \n",
       "\n",
       "    diagnostic  itch   grew   hurt  changed  bleed elevation  \\\n",
       "0          NaN   NaN    NaN    NaN      NaN    NaN       NaN   \n",
       "1          BCC  TRUE  FALSE  False    FALSE  False     FALSE   \n",
       "2          BCC  TRUE    UNK   True      UNK   True     FALSE   \n",
       "3          BCC  TRUE   TRUE  False     TRUE   True      TRUE   \n",
       "4          BCC  TRUE    UNK  False      UNK  False      TRUE   \n",
       "..         ...   ...    ...    ...      ...    ...       ...   \n",
       "125        SEK  TRUE   TRUE  False     TRUE  False      TRUE   \n",
       "126        NaN   NaN    NaN    NaN      NaN    NaN       NaN   \n",
       "127        NaN   NaN    NaN    NaN      NaN    NaN       NaN   \n",
       "128        NaN   NaN    NaN    NaN      NaN    NaN       NaN   \n",
       "129        NaN   NaN    NaN    NaN      NaN    NaN       NaN   \n",
       "\n",
       "                    img_id biopsed  \n",
       "0                      NaN     NaN  \n",
       "1        PAT_38_54_234.png    True  \n",
       "2         PAT_42_58_13.png    True  \n",
       "3       PAT_46_881_939.png    True  \n",
       "4       PAT_98_152_562.png    True  \n",
       "..                     ...     ...  \n",
       "125  PAT_2109_4598_112.png   False  \n",
       "126                    NaN     NaN  \n",
       "127                    NaN     NaN  \n",
       "128                    NaN     NaN  \n",
       "129                    NaN     NaN  \n",
       "\n",
       "[130 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "data_path = r\"C:\\Users\\serru\\OneDrive\\Documents\\Project2\\Project-2-Medical-Imaging\\data\\full_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\pandas\\core\\indexing.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "#new_frame = pd.DataFrame(data = df[\"img_id\"], columns = df[\"diagnostic\"])\n",
    "#new_frame\n",
    "\n",
    "new_df=df[['img_id','diagnostic']]\n",
    "new_df.loc[new_df['diagnostic'].isin(['BCC', 'MEL', 'SCC']), 'diagnostic'] = int(1)\n",
    "new_df.loc[new_df['diagnostic'].isin(['ACK', 'NEV', 'SEK']), 'diagnostic'] = int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "\n",
    "import Functions2\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "folder_path_in = 'C:\\\\Users\\\\serru\\\\OneDrive\\\\Documents\\\\Project2\\\\Project-2-Medical-Imaging\\\\data\\\\ColorMask\\\\Test'\n",
    "\n",
    "def extract_features(folder_path_in):\n",
    "    # Create a list of image filenames\n",
    "    feature_1 = []\n",
    "    feature_2 = []\n",
    "    feature_3 = []\n",
    "    feature_4 = []\n",
    "    feature_5 = []\n",
    "    feature_6 = []\n",
    "    feature_7 = []\n",
    "    #Iterate through all the jpg and png files in the selected folder\n",
    "    for filename in [f for f in os.listdir(folder_path_in) if f.endswith('.jpg') or f.endswith('.png')]:\n",
    "        \n",
    "        #Read in the image\n",
    "        image_path = folder_path_in + \"/\" + filename\n",
    "        original = io.imread(image_path)\n",
    "\n",
    "        # Ignore the alpha channel (e.g. transparency )\n",
    "        if original.shape[-1] == 4:\n",
    "            original = original[..., :3]\n",
    "        \n",
    "        feature_1.append(Functions2.measure_pigment_network(original))\n",
    "        feature_2.append(Functions2.measure_blue_veil(original))\n",
    "        feature_3.append(Functions2.measure_vascular(original))\n",
    "        feature_4.append(Functions2.measure_globules(original))\n",
    "        feature_5.append(Functions2.measure_streaks(original))\n",
    "        feature_6.append(Functions2.measure_irregular_pigmentation(original))\n",
    "        feature_7.append(Functions2.measure_regression(original))\n",
    "    return feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7\n",
    "\n",
    "   \n",
    "feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7 = extract_features(folder_path_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.36029052734375, 3.3447265625, 2.11181640625, 18.10150146484375, 3.1158447265625, 3.48358154296875, 5.12847900390625, 9.06524658203125, 15.87982177734375, 17.93975830078125, 13.848876953125, 17.401123046875] [3376, 756, 749, 10242, 1142, 3250, 2915, 8416, 14553, 3347, 11660, 789] [7159, 1646, 298, 13308, 1291, 2285, 1337, 8744, 1356, 2, 40, 10734] [123, 38, 39, 89, 25, 34, 50, 70, 219, 92, 146, 105] [1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628, 1.2732395447351628] [9.97772216796875, 4.62646484375, 2.96173095703125, 25.9979248046875, 4.217529296875, 5.10711669921875, 5.8319091796875, 12.64190673828125, 23.09722900390625, 26.6387939453125, 19.79827880859375, 25.77972412109375] [1, 0, 20, 0, 0, 0, 0, 0, 30, 398, 1384, 0]\n"
     ]
    }
   ],
   "source": [
    "print(feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "features_df = pd.DataFrame()\n",
    "for filename in os.listdir(folder_path_in):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "        file_names.append(filename)\n",
    "\n",
    "features_df = pd.DataFrame({'img_id': file_names})\n",
    "\n",
    "def featurized_df(feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7):\n",
    "   \n",
    "\n",
    "\n",
    "    features_df[\"1: pigment network\"] = feature_1\n",
    "    features_df[\"2: Blue veil\"] = feature_2\n",
    "    features_df[\"3: Vascular\"] = feature_3\n",
    "    features_df[\"4: Globules\"] = feature_4\n",
    "    features_df[\"5: Streaks\"] = feature_5\n",
    "    features_df[\"6: Pigmentation\"] = feature_6\n",
    "    features_df[\"7: Regression\"] = feature_7\n",
    "\n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df1 and df2 are your DataFrames\n",
    "# Assuming 'img_id' is the column name containing the image IDs\n",
    "\n",
    "# Check if the img_id values are the same in both DataFrames\n",
    "df_merged = pd.merge(new_df, features_df, on='img_id', how='inner')\n",
    "\n",
    "# Create a new column called 'diagnosed' based on the comparison\n",
    "#df_merged['diagnosed'] = True\n",
    "\n",
    "# If you want to fill the 'diagnosed' column with False for non-matching img_id values, uncomment the following line:\n",
    "#df_merged['diagnosed'].fillna(False, inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_merged.copy()\n",
    "X.drop(\"img_id\", axis = 1, inplace = True)\n",
    "X.drop(\"diagnostic\", axis = 1, inplace = True)\n",
    "Y = df_merged[\"diagnostic\"].astype(int)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6, 0)\n",
      "Y_train shape: (6,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Create and train the DecisionTreeClassifier\u001b[39;00m\n\u001b[0;32m     19\u001b[0m classifier \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[1;32m---> 20\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\tree\\_classes.py:186\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    184\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 186\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    187\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    188\u001b[0m )\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    190\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_X_params:\n\u001b[0;32m    578\u001b[0m     check_X_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 579\u001b[0m X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params)\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_y_params:\n\u001b[0;32m    581\u001b[0m     check_y_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[0;32m    780\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[39m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check for missing values in X_train and Y_train\n",
    "if np.any(np.isnan(X_train)) or np.any(np.isnan(Y_train)):\n",
    "    # Handle missing values in X_train\n",
    "    imputer = SimpleImputer()\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "    # Handle missing values in Y_train (if applicable)\n",
    "    Y_train = imputer.fit_transform(Y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Verify the shapes of X_train and Y_train\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "\n",
    "# Create and train the DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m classifier \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[0;32m      4\u001b[0m \u001b[39m#Training the classifier\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m classifier \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m      7\u001b[0m prediction \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\tree\\_classes.py:186\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    184\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 186\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    187\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    188\u001b[0m )\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    190\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_X_params:\n\u001b[0;32m    578\u001b[0m     check_X_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 579\u001b[0m X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params)\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_y_params:\n\u001b[0;32m    581\u001b[0m     check_y_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32mc:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[0;32m    780\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[39m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "#Training the classifier\n",
    "classifier = classifier.fit(X_train, Y_train)\n",
    "\n",
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "cm = confusion_matrix(Y_test, prediction, labels = [0, 1])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "feature_names = X.columns\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "_ = tree.plot_tree(classifier, feature_names= feature_names, class_names= {0:\"cancer\",1: \"no cancer\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cla = LogisticRegression()\n",
    "\n",
    "cla = cla.fit(X_train, Y_train)\n",
    "prediction = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, prediction, labels = [0, 1])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classif = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "classif = cla.fit(X_train, Y_train)\n",
    "pred = classifier.predict(X_test)\n",
    "conf = confusion_matrix(Y_test, pred, labels = [0, 1])\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "\n",
    "# Perform cross-validation for Linear Regression\n",
    "linear_regression_scores = cross_val_score(cla, X_train, Y_train, cv=5)\n",
    "linear_regression_mean_accuracy = linear_regression_scores.mean()\n",
    "\n",
    "# Perform cross-validation for KNN\n",
    "knn_scores = cross_val_score(classif, X_train, Y_train, cv=5)\n",
    "knn_mean_accuracy = knn_scores.mean()\n",
    "\n",
    "# Perform cross-validation for Decision Tree\n",
    "tree_scores = cross_val_score(classifier, X_train, Y_train, cv=5)\n",
    "tree_mean_accuracy = tree_scores.mean()\n",
    "\n",
    "# Calculate F1 score for Linear Regression\n",
    "y_pred_linear_regression = cla.predict(X_test)\n",
    "y_pred_linear_regression = [0 if val < 0.5 else 1 for val in y_pred_linear_regression]\n",
    "f1_linear_regression = f1_score(Y_test, y_pred_linear_regression)\n",
    "\n",
    "# Calculate F1 score for KNN\n",
    "y_pred_knn = classif.predict(X_test)\n",
    "f1_knn = f1_score(Y_test, y_pred_knn)\n",
    "\n",
    "# Calculate F1 score for Tree\n",
    "y_pred_tree = classifier.predict(X_test)\n",
    "f1_tree = f1_score(Y_test, y_pred_tree)\n",
    "\n",
    "# Calculate AUC-ROC score for Linear Regression\n",
    "auc_roc_linear_regression = roc_auc_score(Y_test, y_pred_linear_regression)\n",
    "\n",
    "# Calculate AUC-ROC score for KNN\n",
    "auc_roc_knn = roc_auc_score(Y_test, y_pred_knn)\n",
    "\n",
    "# Calculate AUC-ROC score for KNN\n",
    "auc_roc_tree = roc_auc_score(Y_test, y_pred_tree)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Linear Regression Cross-Validation Accuracy:\", linear_regression_mean_accuracy)\n",
    "print(\"KNN Cross-Validation Accuracy:\", knn_mean_accuracy)\n",
    "print(\"Tree Cross-Validation Accuracy:\", tree_mean_accuracy)\n",
    "print(\"Linear Regression F1 Score:\", f1_linear_regression)\n",
    "print(\"KNN F1 Score:\", f1_knn)\n",
    "print(\"Tree F1 Score:\", f1_tree)\n",
    "print(\"Linear Regression AUC-ROC Score:\", auc_roc_linear_regression)\n",
    "print(\"KNN AUC-ROC Score:\", auc_roc_knn)\n",
    "print(\"Tree AUC-ROC Score:\", auc_roc_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the classifier\n",
    "import pickle\n",
    "pickle.dump(classif, open(\"C:/Users/annam/Desktop/Trained_classifiers/KNN_2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annam\\Desktop\\ITU\\2nd_sem\\02_First_Year_Project\\2nd_project\\Project-2-Medical-Imaging\\src\\functions.py:160: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circularity = 4 * 3.1415 * (area / (perimeter ** 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but KNeighborsClassifier is expecting 7 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m image_features \u001b[39m=\u001b[39m extract_features(image_path)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Make the prediction using the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(image_features)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Convert the numerical prediction back to the corresponding label\u001b[39;00m\n\u001b[0;32m     18\u001b[0m label_mapping \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbenign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmalignant\u001b[39m\u001b[39m'\u001b[39m}\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:806\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    804\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    805\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 806\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    808\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[0;32m    809\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\annam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8 features, but KNeighborsClassifier is expecting 7 features as input."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the trained model from the saved file\n",
    "with open(\"C:/Users/annam/Desktop/Trained_classifiers/KNN_2.pkl\", 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Assuming you have a new image to predict\n",
    "image_path = \"C:/Users/annam/Desktop/Vascular/Masked\"\n",
    "\n",
    "\n",
    "# Extract features from the preprocessed image\n",
    "image_features = extract_features(image_path)\n",
    "\n",
    "# Make the prediction using the model\n",
    "prediction = model.predict(image_features)\n",
    "\n",
    "# Convert the numerical prediction back to the corresponding label\n",
    "label_mapping = {0: 'benign', 1: 'malignant'}\n",
    "predicted_label = label_mapping[prediction[0]]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = pickle.load(open(\"C:/Users/annam/Desktop/Trained_classifiers/KNN.pkl\", \"rb\"))\n",
    "KNN_model.predict(io.imread(\"C:/Users/annam/Desktop/Vascular/Masked/image5.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
